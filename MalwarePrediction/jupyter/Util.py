import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import sys
import os.path
import time
import pickle
from sinfo import sinfo
import Util

from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve, auc


'''
<summary>Get columns to drop from given dataframe, provided with columns contains null values.
<parameter namse ='dataframe'>The dataframe.
<parameter name ='null_columns'>List of columns contains null values.
<parameter name ='nan_threshold'>The threshold used to drop columns contains NaN values. Default is 50% of total data point.
<parameter name ='unique_count_threshold'>The trheshold used to drop columns contains unique value count. Default is 90% of total data point.
'''
def get_columns_to_drop(dataframe, null_columns, nan_threshold=0.5, unique_count_threshold=0.9):
    # variable to hold columns to be dropped
    drop_columns = []
    total_row_count = dataframe.shape[0]
    threshold = round(total_row_count * nan_threshold)

    # loop over the null columns in the dataframe
    for column in dataframe[null_columns].columns:
        unique_count = dataframe[column].nunique()
        print("column:{0}, unique value count:{1}".format(column, unique_count))

        if dataframe[column].isnull().sum() > threshold:
            drop_columns.append(column)

        if unique_count == 1:
            drop_columns.append(column)

        if unique_count > 2 and (unique_count / total_row_count) > unique_count_threshold:
            drop_columns.append(column)

    return drop_columns


'''
<summary>A function fill in NaN values with either mode, median, or empty string. Returns True if successful.
<parameter name ='dataframe'>The dataframe.
<parameter name ='columns'>List of columns of the dataframe.
<parameter name ='action'>Use mode, median, or emtpy string to fill in NaN values. Default action does nothing.
<:return> True if sucessful.
'''
def fillInNaN(dataframe, columns, action='default'):
    result = False
    try:
        for column in columns:
            if action.strip().lower() == 'mode':
                dataframe[column] = dataframe[column].fillna(dataframe[column].mode()[0])
                result = True
            elif action.strip().lower() == 'median':
                dataframe[column] = dataframe[column].fillna(dataframe[column].median())
                result = True
            elif action.strip() == '':
                dataframe[column] = dataframe[column].replace(np.nan, '', regex=True)
                result = True
            else:
                display("No actions occured.")
    except:
        print("Error:{0} occured".format(sys.exc_info()[0]))

    return result

'''
<summary> Get unique values per column.
<parameter name='dataframe'> The dataframe.
<:parameter name ='columns'> List of columns.
<:return> A dictionary contains key:column name, value: unique values.
'''
def getUniqueValuesPerColumn(dataframe, columns):
    unique_values_dic = {}

    for column in columns:
        unique_values_dic[column] = dataframe[column].unique()

    return unique_values_dic

'''
<summary> Plot out confustion matrix.
<:parameter name='y_test'> Array of y test data.
<:parameter name ='y_predict'> Array of y predicted data.
'''
def plotConfustionMatrix(y_test,y_predict):
    sns.set()
    cm = confusion_matrix(y_test, y_predict)
    print(cm)
    plt.subplots(figsize=(10,10))
    ax = sns.heatmap(cm, annot=True, linewidths=.5, cmap="YlGnBu")

'''
<summary> Perform sklearn train_test_split() and return list of train, test data.
<:parameter name='dataframe'> The dataframe used to do train test split.
<:parameter name ='predicted_column'> Name of the predicted column of the dataframe. To be excluded.
<:parameter name ='test_size'> Size of the test data.
<:return> A list of train, test data array.
'''
def trainTestSplit(dataframe, predicted_column, test_size):
    start_time = time.time()
    # fit model with numeric values first
    X = dataframe.loc[:, dataframe.columns != predicted_column]
    y = dataframe.loc[:, dataframe.columns == predicted_column]

    print("Train Test Split: X shape:{0}, y shape:{1}, {2} sec.".format(X.shape,y.shape,time.time()-start_time))

    list_sets = train_test_split(X, y, test_size = test_size, stratify = y)
    return list_sets

'''
<summary> Scale train test data and return them as a list.
<:parameter name ='train_test_list'> The train test data list.
<:parameter name ='scaler'> The scaler used to scale the data.
<:return> A list of scaled data.
'''
def scale(train_test_list, scaler):
    assert len(train_test_list) == 4, "Train test split list length should equal to 4."
    start_time = time.time()

    X_train = train_test_list[0]
    X_test = train_test_list[1]

    # transform the data
    train_test_list[0] = scaler.fit_transform(X_train)
    train_test_list[1] = scaler.transform(X_test)

    print("Finish scaling. {0} sec.".format(time.time() - start_time))
    return list(train_test_list)

'''
<summary> Train the model.
<:parameter name = 'train_test_list'> The train test data list.
<:parameter name = 'model'> The model instance.
<:parameter name ='save_file_name'> File name of saved model.
'''
def trainModel(train_test_list, model, save_file_name):
    assert len(train_test_list) == 4, "Train test split list length should equal to 4."

    start_time = time.time()
    X_train = train_test_list[0]
    y_train = train_test_list[2]

    # train the model
    model.fit(X_train, y_train)

    # save the model to disk
    pickle.dump(model, open(save_file_name, 'wb'))

    print("Train model:{0} sec.".format(time.time() - start_time))

'''
<summary>Perform model prediction, plot out confusion matrix, and print out classification report.
<:parameter name ='train_test_list'> List of train test data.
<:parameter name ='save_file_name'> Saved model file name.
<remark> For classification model only.
'''
def predictModel(train_test_list, save_file_name):
    assert len(train_test_list) == 4, "Train test split list length should equal to 4."
    X_test = train_test_list[1]
    y_test = train_test_list[3]

    # load the model from disk
    loaded_model = pickle.load(open(save_file_name, 'rb'))
    accuracy = loaded_model.score(X_test, y_test)

    print("Predict model accuracy:{0}".format(accuracy))

    # plot out confusion matrix
    y_prediction = loaded_model.predict(X_test)
    plotConfustionMatrix(y_test, y_prediction)

    # display classification report
    print(classification_report(y_test, y_prediction))

'''
<summary> Plot ROC curve and display AUC score.
<:parameter name ='train_test_list'> List of train test data.
<:parameter name ='save_file_name'> File name of the saved model.
'''
def plotROC(train_test_list, save_file_name):
    assert len(train_test_list) == 4, "Train test split list length should equal to 4."

    start_time = time.time()

    X_test = train_test_list[1]
    # y_train = train_test_list[2]
    y_test = train_test_list[3]

    # load the model from disk
    loaded_model = pickle.load(open(save_file_name, 'rb'))
    # Get the probability for each point in the test set.
    probs = loaded_model.predict_proba(X_test)

    # Compute ROC curve and AUC for the one class
    fpr, tpr, _ = roc_curve(y_test, probs[:, 1])
    roc_auc = auc(fpr, tpr)

    print("Compute ROC curve and AUC:{0},{1} sec.".format(roc_auc, time.time() - start_time))
    # Plot the ROC curve.
    plt.figure()
    lw = 2
    plt.plot(fpr, tpr, color='darkorange',
             lw=lw, label='AUC = %0.2f' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC and AUC')
    plt.legend(loc="best")
    plt.show()
    print("AUC score: %3.3f" % roc_auc)

    return roc_auc
